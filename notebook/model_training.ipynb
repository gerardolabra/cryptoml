{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Data Pre-Procesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import kagglehub as kh\n",
    "import os\n",
    "\n",
    "# Modelling\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data from kaggle and create a single data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.10)\n",
      "Path to dataset files: C:\\Users\\gerar\\.cache\\kagglehub\\datasets\\svaningelgem\\crypto-currencies-daily-prices\\versions\\593\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 216550 entries, 0 to 216549\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count   Dtype         \n",
      "---  ------  --------------   -----         \n",
      " 0   ticker  216550 non-null  object        \n",
      " 1   date    216550 non-null  datetime64[ns]\n",
      " 2   open    216550 non-null  float64       \n",
      " 3   high    216550 non-null  float64       \n",
      " 4   low     216550 non-null  float64       \n",
      " 5   close   216550 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4), object(1)\n",
      "memory usage: 9.9+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(216550, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = kh.dataset_download(\"svaningelgem/crypto-currencies-daily-prices\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(path, file)\n",
    "    \n",
    "    # Load the CSV, explicitly parse date column\n",
    "    df = pd.read_csv(file_path, parse_dates=['date'], dtype={'ticker': 'category'})\n",
    "    \n",
    "    df_list.append(df)\n",
    "\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "combined_df = combined_df.sort_values(by=['ticker', 'date'])\n",
    "\n",
    "print(combined_df.info())  \n",
    "combined_df.head()\n",
    "combined_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating features for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ticker       date   open   high    low  close    return  return_lag1  \\\n",
      "19  1INCH 2021-01-27  2.686  2.733  2.233  2.518 -0.062547     0.139101   \n",
      "20  1INCH 2021-01-28  2.518  3.368  2.440  3.122  0.239873    -0.062547   \n",
      "21  1INCH 2021-01-29  3.122  3.500  2.850  3.341  0.070147     0.239873   \n",
      "22  1INCH 2021-01-30  3.341  4.676  3.187  4.565  0.366357     0.070147   \n",
      "23  1INCH 2021-01-31  4.565  5.555  4.468  4.940  0.082147     0.366357   \n",
      "\n",
      "    return_7d   SMA_20    EMA_20  volatility_7d  \n",
      "19   0.053862  1.72500  1.872089       0.144704  \n",
      "20   0.108018  1.82110  1.991128       0.130655  \n",
      "21   0.102576  1.92595  2.119687       0.131435  \n",
      "22   0.139662  2.09300  2.352574       0.165119  \n",
      "23   0.111670  2.28365  2.598996       0.153973  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure chronological order\n",
    "combined_df = combined_df.sort_values(by=[\"ticker\", \"date\"])\n",
    "\n",
    "# 1. Calculate daily returns\n",
    "combined_df[\"return\"] = combined_df.groupby(\"ticker\")[\"close\"].pct_change()\n",
    "\n",
    "# 2. Create lagged returns (previous day's return)\n",
    "combined_df[\"return_lag1\"] = combined_df.groupby(\"ticker\")[\"return\"].shift(1)\n",
    "\n",
    "# 3. Rolling mean return (past 7 days)\n",
    "combined_df[\"return_7d\"] = (\n",
    "    combined_df.groupby(\"ticker\")[\"return\"]\n",
    "    .rolling(window=7)\n",
    "    .mean()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "# 4. Moving Averages (SMA & EMA)\n",
    "combined_df[\"SMA_20\"] = combined_df.groupby(\"ticker\")[\"close\"].transform(\n",
    "    lambda x: x.rolling(window=20).mean()\n",
    ")\n",
    "combined_df[\"EMA_20\"] = combined_df.groupby(\"ticker\")[\"close\"].transform(\n",
    "    lambda x: x.ewm(span=20, adjust=False).mean()\n",
    ")\n",
    "\n",
    "# 5. Rolling Volatility (std dev of returns, 7-day)\n",
    "combined_df[\"volatility_7d\"] = (\n",
    "    combined_df.groupby(\"ticker\")[\"return\"]\n",
    "    .rolling(window=7)\n",
    "    .std()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "# Drop NaNs (from rolling calculations)\n",
    "combined_df = combined_df.dropna()\n",
    "\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date ticker    return  target\n",
      "19 2021-01-27  1INCH -0.062547       1\n",
      "20 2021-01-28  1INCH  0.239873       1\n",
      "21 2021-01-29  1INCH  0.070147       1\n",
      "22 2021-01-30  1INCH  0.366357       1\n",
      "23 2021-01-31  1INCH  0.082147       1\n",
      "24 2021-02-01  1INCH  0.022874       0\n",
      "25 2021-02-02  1INCH -0.076786       1\n",
      "26 2021-02-03  1INCH  0.079743       1\n",
      "27 2021-02-04  1INCH  0.111376       1\n",
      "28 2021-02-05  1INCH  0.040372       0\n"
     ]
    }
   ],
   "source": [
    "# Create target variable: 1 if next day's return is positive, else 0\n",
    "combined_df[\"target\"] = (combined_df.groupby(\"ticker\")[\"return\"].shift(-1) > 0).astype(int)\n",
    "\n",
    "# Drop NaNs (last row for each ticker will have no target)\n",
    "combined_df = combined_df.dropna()\n",
    "\n",
    "print(combined_df[[\"date\", \"ticker\", \"return\", \"target\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features for training\n",
    "features = [\"return_lag1\", \"return_7d\", \"SMA_20\", \"EMA_20\", \"volatility_7d\"]\n",
    "\n",
    "X = combined_df[features]\n",
    "y = combined_df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (171476, 5), Test size: (42870, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train (80%) and test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Print shapes\n",
    "print(f\"Train size: {X_train.shape}, Test size: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.89      0.67     22676\n",
      "           1       0.50      0.12      0.20     20194\n",
      "\n",
      "    accuracy                           0.53     42870\n",
      "   macro avg       0.52      0.51      0.43     42870\n",
      "weighted avg       0.52      0.53      0.45     42870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.5297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.89      0.67     22676\n",
      "           1       0.50      0.12      0.20     20194\n",
      "\n",
      "    accuracy                           0.53     42870\n",
      "   macro avg       0.52      0.51      0.43     42870\n",
      "weighted avg       0.52      0.53      0.45     42870\n",
      "\n",
      "========================================\n",
      "Model: K-Neighbors Classifier\n",
      "Accuracy: 0.5150\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.55      0.54     22676\n",
      "           1       0.49      0.48      0.48     20194\n",
      "\n",
      "    accuracy                           0.52     42870\n",
      "   macro avg       0.51      0.51      0.51     42870\n",
      "weighted avg       0.51      0.52      0.51     42870\n",
      "\n",
      "========================================\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.5127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.53      0.54     22676\n",
      "           1       0.48      0.49      0.49     20194\n",
      "\n",
      "    accuracy                           0.51     42870\n",
      "   macro avg       0.51      0.51      0.51     42870\n",
      "weighted avg       0.51      0.51      0.51     42870\n",
      "\n",
      "========================================\n",
      "Model: Random Forest\n",
      "Accuracy: 0.5329\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.59      0.57     22676\n",
      "           1       0.50      0.47      0.49     20194\n",
      "\n",
      "    accuracy                           0.53     42870\n",
      "   macro avg       0.53      0.53      0.53     42870\n",
      "weighted avg       0.53      0.53      0.53     42870\n",
      "\n",
      "========================================\n",
      "Model: XGBoost\n",
      "Accuracy: 0.5326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.64      0.59     22676\n",
      "           1       0.50      0.41      0.45     20194\n",
      "\n",
      "    accuracy                           0.53     42870\n",
      "   macro avg       0.53      0.53      0.52     42870\n",
      "weighted avg       0.53      0.53      0.53     42870\n",
      "\n",
      "========================================\n",
      "Model: CatBoost\n",
      "Accuracy: 0.5409\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.69      0.61     22676\n",
      "           1       0.52      0.37      0.43     20194\n",
      "\n",
      "    accuracy                           0.54     42870\n",
      "   macro avg       0.54      0.53      0.52     42870\n",
      "weighted avg       0.54      0.54      0.53     42870\n",
      "\n",
      "========================================\n",
      "Model: AdaBoost\n",
      "Accuracy: 0.5346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.74      0.63     22676\n",
      "           1       0.51      0.30      0.38     20194\n",
      "\n",
      "    accuracy                           0.53     42870\n",
      "   macro avg       0.53      0.52      0.50     42870\n",
      "weighted avg       0.53      0.53      0.51     42870\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=False),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # Train model\n",
    "    y_pred = model.predict(X_test)  # Predict\n",
    "\n",
    "    # Evaluate performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"=\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker\n",
      "1INCH    1443\n",
      "AAVE     1533\n",
      "ACH       942\n",
      "ADA      2548\n",
      "ALGO     2000\n",
      "         ... \n",
      "XRP      3619\n",
      "XTZ      2361\n",
      "ZEC      2976\n",
      "ZIL      2418\n",
      "ZRX       975\n",
      "Length: 116, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assuming combined_df is your DataFrame containing the data\n",
    "ticker_counts = combined_df.groupby('ticker').size()\n",
    "\n",
    "# Print the counts for each ticker\n",
    "print(ticker_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
